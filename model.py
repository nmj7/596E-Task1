# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PrOAy1YW2Eq1QMByWyJfLGNXKx4_khy2
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from sklearn.ensemble import IsolationForest
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import OneHotEncoder
import joblib

# Commented out IPython magic to ensure Python compatibility.
# %pip install onnx==1.16.1
# %pip install onnxruntime
# %pip install skl2onnx
# %pip install onnxruntime-gpu
import onnx
import skl2onnx
import onnxruntime as rt
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
from sklearn.ensemble import IsolationForest
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder

#from google.colab import drive
#drive.mount('/content/drive')

df=pd.read_csv(r"financial_anomaly_data.csv")

df.head()

# EDA
# Check for missing values
print(df.isnull().sum())

# Summary statistics
print(df.describe())

# Visualize distribution of Amount
plt.figure(figsize=(10, 6))
sns.histplot(df['Amount'], bins=50, kde=True)
plt.title('Distribution of Transaction Amount')
plt.show()

# Visualize Transaction Type distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='TransactionType', data=df)
plt.title('Transaction Type Distribution')
plt.show()

print(df.columns)

df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%d-%m-%Y %H:%M')

# Use OneHotEncoder for categorical variables
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded_cols = encoder.fit_transform(df[['Merchant', 'TransactionType', 'Location']])
feature_names = encoder.get_feature_names_out(['Merchant', 'TransactionType', 'Location'])
encoded_df = pd.DataFrame(encoded_cols, columns=feature_names)

# Feature engineering - drop original categorical columns
df = pd.concat([df, encoded_df], axis=1)
df.drop(['Merchant', 'TransactionType', 'Location'], axis=1, inplace=True)
df.dropna(inplace=True)

# Fit Isolation Forest model
model = IsolationForest(contamination=0.2, random_state=42)
model.fit(df[['Amount'] + list(encoded_df.columns)])

# Predict anomalies (1 for normal, -1 for anomalies)
df['Anomaly'] = model.predict(df[['Amount'] + list(encoded_df.columns)])

# Check the number of features used by the model
n_features = model.n_features_in_
print(f"Number of features used by the model: {n_features}")

# Convert the model to ONNX format
initial_type = [('float_input', FloatTensorType([None, n_features]))]
onnx_model = convert_sklearn(
    model,
    initial_types=initial_type,
    target_opset={"ai.onnx.ml": 3, "" : 13} # Explicitly set the supported version
)

# Save the ONNX model to a file
onnx_filename = "isolation_forest_model.onnx"
with open(onnx_filename, "wb") as f:
    f.write(onnx_model.SerializeToString())

print(f"Model saved to {onnx_filename}")

#onnxruntime
import numpy as np
import onnxruntime as rt

# Load the ONNX model
sess = rt.InferenceSession("isolation_forest_model.onnx")

# Prepare input data (example)
input_data = df[['Amount'] + list(encoded_df.columns)].values.astype(np.float32)

# Run the model
input_name = sess.get_inputs()[0].name
label_name = sess.get_outputs()[0].name
pred_onx = sess.run([label_name], {input_name: input_data})[0]

print(pred_onx)
